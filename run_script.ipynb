{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "prZbXhmIH6r_",
        "outputId": "e196e2cb-c306-42de-e29e-05b083a62255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'FaithDial'...\n",
            "remote: Enumerating objects: 152, done.\u001b[K\n",
            "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 152 (delta 57), reused 121 (delta 31), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (152/152), 1.03 MiB | 7.08 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/McGill-NLP/FaithDial.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a53LM3MjoAP5",
        "outputId": "dcf6ae68-10ca-4d3c-9d2f-6efbb10b5350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ddkang/loss_dropper.git (from -r /content/FaithDial/requirements.txt (line 5))\n",
            "  Cloning https://github.com/ddkang/loss_dropper.git to /tmp/pip-req-build-pwvmfqk_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ddkang/loss_dropper.git /tmp/pip-req-build-pwvmfqk_\n",
            "  Resolved https://github.com/ddkang/loss_dropper.git to commit 12ea3b8647161bf8e750dac2b9ea622d62b81c1a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytorch-lightning~=1.5.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/FaithDial/requirements.txt (line 1)) (1.5.10)\n",
            "Requirement already satisfied: datasets~=2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/FaithDial/requirements.txt (line 2)) (2.1.0)\n",
            "Requirement already satisfied: transformers~=4.16.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/FaithDial/requirements.txt (line 3)) (4.16.2)\n",
            "Requirement already satisfied: torchmetrics~=0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/FaithDial/requirements.txt (line 4)) (0.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (2.0.0+cu118)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (0.18.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (2023.4.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (2.12.2)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (0.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: setuptools==59.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (59.5.0)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (9.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (0.14.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers~=4.16.0->-r /content/FaithDial/requirements.txt (line 3)) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.16.0->-r /content/FaithDial/requirements.txt (line 3)) (2022.10.31)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers~=4.16.0->-r /content/FaithDial/requirements.txt (line 3)) (0.0.53)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.16.0->-r /content/FaithDial/requirements.txt (line 3)) (0.13.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (0.40.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.*->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.*->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.*->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.*->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.*->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.*->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (16.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets~=2.1.0->-r /content/FaithDial/requirements.txt (line 2)) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers~=4.16.0->-r /content/FaithDial/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers~=4.16.0->-r /content/FaithDial/requirements.txt (line 3)) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers~=4.16.0->-r /content/FaithDial/requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.*->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning~=1.5.0->-r /content/FaithDial/requirements.txt (line 1)) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install jedi>=0.16 setuptools>65.5.1\n",
        "!pip install -r /content/FaithDial/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIMj8_8rIxpA",
        "outputId": "e9a3b152-8e38-4be4-bed9-19c8d1470297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-10 11:19:29.711063: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-10 11:19:31.056670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading: 100% 1.44k/1.44k [00:00<00:00, 1.91MB/s]\n",
            "Downloading: 100% 2.26k/2.26k [00:00<00:00, 1.95MB/s]\n",
            "Downloading: 100% 2.31M/2.31M [00:00<00:00, 5.00MB/s]\n",
            "Downloading: 100% 2.15k/2.15k [00:00<00:00, 2.81MB/s]\n",
            "05/10/2023 11:19:35 - INFO - torch.distributed.nn.jit.instantiator - Created a temporary directory at /tmp/tmpnz8upuiy\n",
            "05/10/2023 11:19:35 - INFO - torch.distributed.nn.jit.instantiator - Writing /tmp/tmpnz8upuiy/_remote_module_non_scriptable.py\n",
            "Downloading: 100% 283M/283M [00:07<00:00, 38.7MB/s]\n",
            "05/10/2023 11:19:45 - INFO - dataset - Loading training examples...\n",
            "Downloading builder script: 100% 6.74k/6.74k [00:00<00:00, 5.58MB/s]\n",
            "Downloading metadata: 100% 3.43k/3.43k [00:00<00:00, 3.14MB/s]\n",
            "05/10/2023 11:19:46 - WARNING - datasets.builder - No config specified, defaulting to: faith_dial_dataset/plain_text\n",
            "Downloading and preparing dataset faith_dial_dataset/plain_text (download: 32.71 MiB, generated: 24.17 MiB, post-processed: Unknown size, total: 56.88 MiB) to /root/.cache/huggingface/datasets/McGill-NLP___faith_dial_dataset/plain_text/1.0.0/70568c8ab3bbc83b603bce58fa593ab27e7f0d0cde51034e1c2073ff3e14189a...\n",
            "Downloading data files:   0% 0/7 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/19.5M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  29% 5.71M/19.5M [00:00<00:00, 57.1MB/s]\u001b[A\n",
            "Downloading data: 100% 19.5M/19.5M [00:00<00:00, 71.6MB/s]\n",
            "Downloading data files:  14% 1/7 [00:00<00:03,  1.66it/s]\n",
            "Downloading data: 100% 3.65M/3.65M [00:00<00:00, 63.3MB/s]\n",
            "Downloading data files:  29% 2/7 [00:00<00:02,  2.16it/s]\n",
            "Downloading data: 100% 1.81M/1.81M [00:00<00:00, 67.4MB/s]\n",
            "Downloading data files:  43% 3/7 [00:01<00:02,  1.68it/s]\n",
            "Downloading data: 100% 1.84M/1.84M [00:00<00:00, 62.9MB/s]\n",
            "Downloading data files:  57% 4/7 [00:02<00:01,  2.05it/s]\n",
            "Downloading data: 100% 3.75M/3.75M [00:00<00:00, 88.4MB/s]\n",
            "Downloading data files:  71% 5/7 [00:02<00:00,  2.31it/s]\n",
            "Downloading data: 100% 1.83M/1.83M [00:00<00:00, 68.1MB/s]\n",
            "Downloading data files:  86% 6/7 [00:02<00:00,  2.51it/s]\n",
            "Downloading data: 100% 1.92M/1.92M [00:00<00:00, 71.0MB/s]\n",
            "Downloading data files: 100% 7/7 [00:03<00:00,  2.31it/s]\n",
            "Extracting data files: 100% 7/7 [00:00<00:00, 2600.08it/s]\n",
            "Dataset faith_dial_dataset downloaded and prepared to /root/.cache/huggingface/datasets/McGill-NLP___faith_dial_dataset/plain_text/1.0.0/70568c8ab3bbc83b603bce58fa593ab27e7f0d0cde51034e1c2073ff3e14189a. Subsequent calls will reuse this data.\n",
            "05/10/2023 11:19:53 - WARNING - datasets.fingerprint - Parameter 'function'=<function ConversationalDataset._map.<locals>.<lambda> at 0x7fac1fcd9900> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "100% 19/19 [00:07<00:00,  2.48ba/s]\n",
            "100% 19/19 [00:07<00:00,  2.41ba/s]\n",
            "05/10/2023 11:20:08 - INFO - dataset - #conversational train examples loaded: 18357\n",
            "05/10/2023 11:20:08 - INFO - dataset - Loading validation examples...\n",
            "05/10/2023 11:20:09 - WARNING - datasets.builder - No config specified, defaulting to: faith_dial_dataset/plain_text\n",
            "05/10/2023 11:20:09 - WARNING - datasets.builder - Reusing dataset faith_dial_dataset (/root/.cache/huggingface/datasets/McGill-NLP___faith_dial_dataset/plain_text/1.0.0/70568c8ab3bbc83b603bce58fa593ab27e7f0d0cde51034e1c2073ff3e14189a)\n",
            "100% 4/4 [00:01<00:00,  2.80ba/s]\n",
            "100% 4/4 [00:01<00:00,  2.96ba/s]\n",
            "05/10/2023 11:20:12 - INFO - dataset - #conversational valid examples loaded: 3417\n",
            "Global seed set to 42\n",
            "Using 16bit native Automatic Mixed Precision (AMP)\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Missing logger folder: /content/train_logs\n",
            "\n",
            "  | Name  | Type                       | Params\n",
            "-----------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 74.2 M\n",
            "-----------------------------------------------------\n",
            "74.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "74.2 M    Total params\n",
            "148.433   Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /content exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "Validation sanity check: 0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Validation sanity check:  50% 1/2 [00:03<00:03,  3.17s/it]***** Validation results *****\n",
            "early stop 0/5 - best = inf\n",
            "valid/loss = tensor(12.8337, device='cuda:0')\n",
            "valid/ppl = tensor(374642.9688, device='cuda:0')\n",
            "\n",
            "Global seed set to 42\n",
            "Epoch 0:  42% 574/1362 [00:41<00:56, 13.91it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  42% 576/1362 [00:41<00:57, 13.76it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  43% 579/1362 [00:41<00:56, 13.79it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  43% 582/1362 [00:42<00:56, 13.83it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  43% 586/1362 [00:42<00:55, 13.88it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  43% 590/1362 [00:42<00:55, 13.91it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  44% 594/1362 [00:42<00:55, 13.95it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Validating:  19% 20/107 [00:01<00:04, 21.30it/s]\u001b[A\n",
            "Epoch 0:  44% 598/1362 [00:42<00:54, 13.99it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  44% 602/1362 [00:42<00:54, 14.03it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  44% 606/1362 [00:43<00:53, 14.07it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Validating:  30% 32/107 [00:01<00:03, 24.27it/s]\u001b[A\n",
            "Epoch 0:  45% 610/1362 [00:43<00:53, 14.10it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  45% 614/1362 [00:43<00:52, 14.14it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  45% 618/1362 [00:43<00:52, 14.18it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Validating:  41% 44/107 [00:02<00:02, 23.16it/s]\u001b[A\n",
            "Epoch 0:  46% 622/1362 [00:43<00:52, 14.21it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  46% 626/1362 [00:43<00:51, 14.25it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  46% 630/1362 [00:44<00:51, 14.29it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Validating:  52% 56/107 [00:02<00:02, 25.13it/s]\u001b[A\n",
            "Epoch 0:  47% 634/1362 [00:44<00:50, 14.33it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  47% 638/1362 [00:44<00:50, 14.37it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  47% 642/1362 [00:44<00:49, 14.42it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Validating:  64% 68/107 [00:03<00:01, 26.55it/s]\u001b[A\n",
            "Epoch 0:  47% 646/1362 [00:44<00:49, 14.46it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  48% 650/1362 [00:44<00:49, 14.50it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  48% 654/1362 [00:44<00:48, 14.54it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  48% 658/1362 [00:45<00:48, 14.59it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Validating:  79% 84/107 [00:03<00:00, 28.03it/s]\u001b[A\n",
            "Epoch 0:  49% 662/1362 [00:45<00:47, 14.63it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  49% 666/1362 [00:45<00:47, 14.67it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  49% 670/1362 [00:45<00:47, 14.70it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Validating:  90% 96/107 [00:04<00:00, 25.81it/s]\u001b[A\n",
            "Epoch 0:  49% 674/1362 [00:45<00:46, 14.74it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  50% 678/1362 [00:45<00:46, 14.78it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]\n",
            "Epoch 0:  50% 682/1362 [00:46<00:46, 14.77it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5]***** Validation results *****\n",
            "early stop 0/5 - best = inf\n",
            "lr = tensor(6.1858e-05, device='cuda:0')\n",
            "train/loss = tensor(6.8289, device='cuda:0')\n",
            "train/lr = tensor(6.1858e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(6.9471, device='cuda:0')\n",
            "valid/ppl = tensor(1040.1718, device='cuda:0')\n",
            "\n",
            "Epoch 0:  50% 682/1362 [00:46<00:46, 14.77it/s, loss=6.98, train/ppl=100.0, lr=6.19e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "                                                 \u001b[ASaving a model at step=143 in epoch=0...\n",
            "Epoch 0:  92% 1256/1362 [01:32<00:07, 13.55it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  92% 1258/1362 [01:33<00:07, 13.51it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  93% 1262/1362 [01:33<00:07, 13.52it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  93% 1266/1362 [01:33<00:07, 13.55it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Validating:   9% 10/107 [00:00<00:05, 17.10it/s]\u001b[A\n",
            "Epoch 0:  93% 1270/1362 [01:33<00:06, 13.57it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  94% 1274/1362 [01:33<00:06, 13.58it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  94% 1278/1362 [01:33<00:06, 13.61it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Validating:  21% 22/107 [00:01<00:03, 22.86it/s]\u001b[A\n",
            "Epoch 0:  94% 1282/1362 [01:34<00:05, 13.62it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  94% 1286/1362 [01:34<00:05, 13.64it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  95% 1290/1362 [01:34<00:05, 13.66it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Validating:  32% 34/107 [00:01<00:03, 24.31it/s]\u001b[A\n",
            "Epoch 0:  95% 1294/1362 [01:34<00:04, 13.67it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  95% 1298/1362 [01:34<00:04, 13.69it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  96% 1302/1362 [01:35<00:04, 13.70it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Validating:  43% 46/107 [00:02<00:02, 21.19it/s]\u001b[A\n",
            "Epoch 0:  96% 1306/1362 [01:35<00:04, 13.72it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  96% 1310/1362 [01:35<00:03, 13.74it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  96% 1314/1362 [01:35<00:03, 13.76it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Validating:  54% 58/107 [00:02<00:01, 24.75it/s]\u001b[A\n",
            "Epoch 0:  97% 1318/1362 [01:35<00:03, 13.78it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  97% 1322/1362 [01:35<00:02, 13.80it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  97% 1326/1362 [01:35<00:02, 13.82it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Validating:  65% 70/107 [00:03<00:01, 24.95it/s]\u001b[A\n",
            "Epoch 0:  98% 1330/1362 [01:36<00:02, 13.83it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  98% 1334/1362 [01:36<00:02, 13.85it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  98% 1338/1362 [01:36<00:01, 13.88it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  99% 1342/1362 [01:36<00:01, 13.89it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Validating:  80% 86/107 [00:03<00:00, 26.09it/s]\u001b[A\n",
            "Epoch 0:  99% 1346/1362 [01:36<00:01, 13.91it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  99% 1350/1362 [01:36<00:00, 13.93it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0:  99% 1354/1362 [01:37<00:00, 13.95it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Validating:  92% 98/107 [00:04<00:00, 24.07it/s]\u001b[A\n",
            "Epoch 0: 100% 1358/1362 [01:37<00:00, 13.97it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Epoch 0: 100% 1362/1362 [01:37<00:00, 13.99it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.950, valid/ppl=1.04e+3]\n",
            "Validating: 100% 107/107 [00:04<00:00, 18.26it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 1040.1717529296875\n",
            "lr = tensor(5.8613e-05, device='cuda:0')\n",
            "train/loss = tensor(5.7361, device='cuda:0')\n",
            "train/lr = tensor(5.8613e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(6.4602, device='cuda:0')\n",
            "valid/ppl = tensor(639.2034, device='cuda:0')\n",
            "\n",
            "Epoch 0: 100% 1362/1362 [01:37<00:00, 13.95it/s, loss=6.6, train/ppl=100.0, lr=5.86e-5, valid/loss=6.460, valid/ppl=639.0]  \n",
            "                                                 \u001b[ASaving a model at step=286 in epoch=0...\n",
            "Epoch 1:  42% 574/1362 [00:42<00:58, 13.42it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  42% 576/1362 [00:43<00:58, 13.34it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  43% 580/1362 [00:43<00:58, 13.37it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Validating:   6% 6/107 [00:00<00:08, 11.93it/s]\u001b[A\n",
            "Epoch 1:  43% 584/1362 [00:43<00:57, 13.42it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  43% 588/1362 [00:43<00:57, 13.46it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  43% 592/1362 [00:43<00:57, 13.50it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Validating:  17% 18/107 [00:01<00:03, 22.39it/s]\u001b[A\n",
            "Epoch 1:  44% 596/1362 [00:43<00:56, 13.55it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  44% 600/1362 [00:44<00:56, 13.59it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  44% 604/1362 [00:44<00:55, 13.63it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Validating:  28% 30/107 [00:01<00:03, 24.13it/s]\u001b[A\n",
            "Epoch 1:  45% 608/1362 [00:44<00:55, 13.67it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  45% 612/1362 [00:44<00:54, 13.69it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  45% 616/1362 [00:44<00:54, 13.72it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Validating:  39% 42/107 [00:02<00:02, 21.70it/s]\u001b[A\n",
            "Epoch 1:  46% 620/1362 [00:45<00:53, 13.75it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  46% 624/1362 [00:45<00:53, 13.79it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  46% 628/1362 [00:45<00:53, 13.82it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Validating:  50% 54/107 [00:02<00:02, 21.33it/s]\u001b[A\n",
            "Epoch 1:  46% 632/1362 [00:45<00:52, 13.86it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  47% 636/1362 [00:45<00:52, 13.88it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  47% 640/1362 [00:45<00:51, 13.92it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Validating:  62% 66/107 [00:03<00:01, 23.39it/s]\u001b[A\n",
            "Epoch 1:  47% 644/1362 [00:46<00:51, 13.96it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  48% 648/1362 [00:46<00:51, 13.99it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  48% 652/1362 [00:46<00:50, 14.02it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Validating:  73% 78/107 [00:03<00:01, 23.06it/s]\u001b[A\n",
            "Epoch 1:  48% 656/1362 [00:46<00:50, 14.06it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  48% 660/1362 [00:46<00:49, 14.10it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  49% 664/1362 [00:46<00:49, 14.13it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Validating:  84% 90/107 [00:04<00:00, 23.32it/s]\u001b[A\n",
            "Epoch 1:  49% 668/1362 [00:47<00:48, 14.17it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  49% 672/1362 [00:47<00:48, 14.20it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Epoch 1:  50% 676/1362 [00:47<00:48, 14.24it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]\n",
            "Validating:  95% 102/107 [00:04<00:00, 24.51it/s]\u001b[A\n",
            "Epoch 1:  50% 680/1362 [00:47<00:47, 14.27it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.460, valid/ppl=639.0]***** Validation results *****\n",
            "early stop 0/5 - best = 639.2034301757812\n",
            "lr = tensor(5.5344e-05, device='cuda:0')\n",
            "train/loss = tensor(6.5386, device='cuda:0')\n",
            "train/lr = tensor(5.5344e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(6.2381, device='cuda:0')\n",
            "valid/ppl = tensor(511.8865, device='cuda:0')\n",
            "\n",
            "Epoch 1:  50% 682/1362 [00:48<00:47, 14.21it/s, loss=6.36, train/ppl=100.0, lr=5.53e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "                                                 \u001b[ASaving a model at step=430 in epoch=1...\n",
            "Epoch 1:  92% 1256/1362 [01:35<00:08, 13.12it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:   1% 1/107 [00:00<01:07,  1.58it/s]\u001b[A\n",
            "Epoch 1:  93% 1260/1362 [01:36<00:07, 13.06it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  93% 1264/1362 [01:36<00:07, 13.07it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  93% 1268/1362 [01:36<00:07, 13.09it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Validating:  11% 12/107 [00:01<00:06, 15.33it/s]\u001b[A\n",
            "Epoch 1:  93% 1272/1362 [01:37<00:06, 13.10it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  94% 1276/1362 [01:37<00:06, 13.12it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Validating:  19% 20/107 [00:01<00:04, 19.31it/s]\u001b[A\n",
            "Epoch 1:  94% 1280/1362 [01:37<00:06, 13.14it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  94% 1284/1362 [01:37<00:05, 13.15it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  95% 1288/1362 [01:37<00:05, 13.17it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Validating:  30% 32/107 [00:02<00:03, 20.83it/s]\u001b[A\n",
            "Epoch 1:  95% 1292/1362 [01:38<00:05, 13.18it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  95% 1296/1362 [01:38<00:05, 13.19it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  95% 1300/1362 [01:38<00:04, 13.20it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Validating:  41% 44/107 [00:02<00:03, 19.58it/s]\u001b[A\n",
            "Epoch 1:  96% 1304/1362 [01:38<00:04, 13.22it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  96% 1308/1362 [01:38<00:04, 13.23it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Validating:  49% 52/107 [00:03<00:02, 20.70it/s]\u001b[A\n",
            "Epoch 1:  96% 1312/1362 [01:39<00:03, 13.25it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  97% 1316/1362 [01:39<00:03, 13.27it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  97% 1320/1362 [01:39<00:03, 13.29it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Validating:  60% 64/107 [00:03<00:01, 23.97it/s]\u001b[A\n",
            "Epoch 1:  97% 1324/1362 [01:39<00:02, 13.31it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  98% 1328/1362 [01:39<00:02, 13.32it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  98% 1332/1362 [01:39<00:02, 13.34it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Validating:  71% 76/107 [00:04<00:01, 25.19it/s]\u001b[A\n",
            "Epoch 1:  98% 1336/1362 [01:39<00:01, 13.37it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  98% 1340/1362 [01:40<00:01, 13.39it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  99% 1344/1362 [01:40<00:01, 13.40it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1:  99% 1348/1362 [01:40<00:01, 13.42it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Validating:  86% 92/107 [00:04<00:00, 25.88it/s]\u001b[A\n",
            "Epoch 1:  99% 1352/1362 [01:40<00:00, 13.44it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1: 100% 1356/1362 [01:40<00:00, 13.46it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Epoch 1: 100% 1360/1362 [01:40<00:00, 13.48it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.240, valid/ppl=512.0]\n",
            "Validating:  97% 104/107 [00:05<00:00, 25.53it/s]\u001b[A\n",
            "Validating: 100% 107/107 [00:05<00:00, 18.08it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 511.8865051269531\n",
            "lr = tensor(5.2098e-05, device='cuda:0')\n",
            "train/loss = tensor(6.6303, device='cuda:0')\n",
            "train/lr = tensor(5.2098e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(6.0732, device='cuda:0')\n",
            "valid/ppl = tensor(434.0887, device='cuda:0')\n",
            "\n",
            "Epoch 1: 100% 1362/1362 [01:41<00:00, 13.45it/s, loss=6.1, train/ppl=100.0, lr=5.21e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "                                                 \u001b[ASaving a model at step=573 in epoch=1...\n",
            "Epoch 2:  42% 574/1362 [00:42<00:58, 13.37it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  42% 576/1362 [00:43<00:59, 13.28it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  43% 580/1362 [00:43<00:58, 13.32it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  43% 584/1362 [00:43<00:58, 13.36it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Validating:   9% 10/107 [00:00<00:05, 16.72it/s]\u001b[A\n",
            "Epoch 2:  43% 588/1362 [00:43<00:57, 13.41it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  43% 592/1362 [00:44<00:57, 13.45it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  44% 596/1362 [00:44<00:56, 13.49it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Validating:  21% 22/107 [00:01<00:03, 22.65it/s]\u001b[A\n",
            "Epoch 2:  44% 600/1362 [00:44<00:56, 13.53it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  44% 604/1362 [00:44<00:55, 13.57it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  45% 608/1362 [00:44<00:55, 13.61it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Validating:  32% 34/107 [00:01<00:03, 24.05it/s]\u001b[A\n",
            "Epoch 2:  45% 612/1362 [00:44<00:55, 13.63it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  45% 616/1362 [00:45<00:54, 13.67it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  46% 620/1362 [00:45<00:54, 13.70it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Validating:  43% 46/107 [00:02<00:02, 21.41it/s]\u001b[A\n",
            "Epoch 2:  46% 624/1362 [00:45<00:53, 13.74it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  46% 628/1362 [00:45<00:53, 13.78it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  46% 632/1362 [00:45<00:52, 13.82it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Validating:  54% 58/107 [00:02<00:01, 24.99it/s]\u001b[A\n",
            "Epoch 2:  47% 636/1362 [00:45<00:52, 13.86it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  47% 640/1362 [00:46<00:51, 13.90it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  47% 644/1362 [00:46<00:51, 13.94it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Validating:  65% 70/107 [00:03<00:01, 25.18it/s]\u001b[A\n",
            "Epoch 2:  48% 648/1362 [00:46<00:51, 13.98it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  48% 652/1362 [00:46<00:50, 14.02it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  48% 656/1362 [00:46<00:50, 14.06it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  48% 660/1362 [00:46<00:49, 14.10it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Validating:  80% 86/107 [00:03<00:00, 26.20it/s]\u001b[A\n",
            "Epoch 2:  49% 664/1362 [00:46<00:49, 14.13it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  49% 668/1362 [00:47<00:48, 14.17it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  49% 672/1362 [00:47<00:48, 14.20it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Validating:  92% 98/107 [00:04<00:00, 24.31it/s]\u001b[A\n",
            "Epoch 2:  50% 676/1362 [00:47<00:48, 14.24it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Epoch 2:  50% 680/1362 [00:47<00:47, 14.28it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=6.070, valid/ppl=434.0]\n",
            "Validating: 100% 107/107 [00:04<00:00, 18.24it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 434.08868408203125\n",
            "lr = tensor(4.8830e-05, device='cuda:0')\n",
            "train/loss = tensor(6.0730, device='cuda:0')\n",
            "train/lr = tensor(4.8830e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.9583, device='cuda:0')\n",
            "valid/ppl = tensor(386.9411, device='cuda:0')\n",
            "\n",
            "Epoch 2:  50% 682/1362 [00:47<00:47, 14.25it/s, loss=5.97, train/ppl=100.0, lr=4.88e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "                                                 \u001b[ASaving a model at step=717 in epoch=2...\n",
            "Epoch 2:  92% 1256/1362 [01:35<00:08, 13.18it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  93% 1260/1362 [01:35<00:07, 13.15it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating:   4% 4/107 [00:00<00:13,  7.86it/s]\u001b[A\n",
            "Epoch 2:  93% 1264/1362 [01:36<00:07, 13.16it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  93% 1268/1362 [01:36<00:07, 13.19it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  93% 1272/1362 [01:36<00:06, 13.20it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating:  15% 16/107 [00:01<00:04, 20.16it/s]\u001b[A\n",
            "Epoch 2:  94% 1276/1362 [01:36<00:06, 13.22it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  94% 1280/1362 [01:36<00:06, 13.24it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  94% 1284/1362 [01:36<00:05, 13.26it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating:  26% 28/107 [00:01<00:03, 22.92it/s]\u001b[A\n",
            "Epoch 2:  95% 1288/1362 [01:36<00:05, 13.28it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  95% 1292/1362 [01:37<00:05, 13.29it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  95% 1296/1362 [01:37<00:04, 13.31it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating:  37% 40/107 [00:02<00:03, 21.30it/s]\u001b[A\n",
            "Epoch 2:  95% 1300/1362 [01:37<00:04, 13.33it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  96% 1304/1362 [01:37<00:04, 13.34it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  96% 1308/1362 [01:37<00:04, 13.36it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating:  49% 52/107 [00:02<00:02, 23.02it/s]\u001b[A\n",
            "Epoch 2:  96% 1312/1362 [01:38<00:03, 13.38it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  97% 1316/1362 [01:38<00:03, 13.40it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  97% 1320/1362 [01:38<00:03, 13.42it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating:  60% 64/107 [00:03<00:01, 25.16it/s]\u001b[A\n",
            "Epoch 2:  97% 1324/1362 [01:38<00:02, 13.44it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  98% 1328/1362 [01:38<00:02, 13.46it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  98% 1332/1362 [01:38<00:02, 13.47it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating:  71% 76/107 [00:03<00:01, 23.44it/s]\u001b[A\n",
            "Epoch 2:  98% 1336/1362 [01:39<00:01, 13.49it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  98% 1340/1362 [01:39<00:01, 13.50it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  99% 1344/1362 [01:39<00:01, 13.52it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating:  82% 88/107 [00:04<00:00, 22.15it/s]\u001b[A\n",
            "Epoch 2:  99% 1348/1362 [01:39<00:01, 13.53it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2:  99% 1352/1362 [01:39<00:00, 13.55it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Epoch 2: 100% 1356/1362 [01:39<00:00, 13.57it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating:  93% 100/107 [00:04<00:00, 23.40it/s]\u001b[A\n",
            "Epoch 2: 100% 1360/1362 [01:40<00:00, 13.59it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.960, valid/ppl=387.0]\n",
            "Validating:  99% 106/107 [00:04<00:00, 24.36it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 386.94110107421875\n",
            "lr = tensor(4.5584e-05, device='cuda:0')\n",
            "train/loss = tensor(5.5510, device='cuda:0')\n",
            "train/lr = tensor(4.5584e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.8455, device='cuda:0')\n",
            "valid/ppl = tensor(345.6643, device='cuda:0')\n",
            "\n",
            "Epoch 2: 100% 1362/1362 [01:40<00:00, 13.55it/s, loss=5.78, train/ppl=100.0, lr=4.56e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "                                                 \u001b[ASaving a model at step=860 in epoch=2...\n",
            "Epoch 3:  42% 574/1362 [00:42<00:58, 13.52it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  42% 576/1362 [00:43<00:58, 13.33it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  43% 580/1362 [00:43<00:58, 13.36it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating:   6% 6/107 [00:00<00:11,  8.55it/s]\u001b[A\n",
            "Epoch 3:  43% 584/1362 [00:43<00:58, 13.40it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  43% 588/1362 [00:43<00:57, 13.44it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  43% 592/1362 [00:43<00:57, 13.46it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating:  17% 18/107 [00:01<00:05, 17.52it/s]\u001b[A\n",
            "Epoch 3:  44% 596/1362 [00:44<00:56, 13.50it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  44% 600/1362 [00:44<00:56, 13.53it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  44% 604/1362 [00:44<00:55, 13.56it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating:  28% 30/107 [00:02<00:03, 20.10it/s]\u001b[A\n",
            "Epoch 3:  45% 608/1362 [00:44<00:55, 13.59it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  45% 612/1362 [00:44<00:55, 13.61it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating:  36% 38/107 [00:02<00:03, 19.06it/s]\u001b[A\n",
            "Epoch 3:  45% 616/1362 [00:45<00:54, 13.64it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  46% 620/1362 [00:45<00:54, 13.66it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating:  43% 46/107 [00:02<00:03, 19.04it/s]\u001b[A\n",
            "Epoch 3:  46% 624/1362 [00:45<00:53, 13.70it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  46% 628/1362 [00:45<00:53, 13.73it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  46% 632/1362 [00:45<00:53, 13.76it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating:  54% 58/107 [00:03<00:02, 22.14it/s]\u001b[A\n",
            "Epoch 3:  47% 636/1362 [00:46<00:52, 13.79it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  47% 640/1362 [00:46<00:52, 13.83it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  47% 644/1362 [00:46<00:51, 13.86it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating:  65% 70/107 [00:04<00:01, 21.72it/s]\u001b[A\n",
            "Epoch 3:  48% 648/1362 [00:46<00:51, 13.89it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  48% 652/1362 [00:46<00:50, 13.94it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  48% 656/1362 [00:46<00:50, 13.98it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  48% 660/1362 [00:47<00:50, 14.02it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating:  80% 86/107 [00:04<00:00, 25.76it/s]\u001b[A\n",
            "Epoch 3:  49% 664/1362 [00:47<00:49, 14.06it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  49% 668/1362 [00:47<00:49, 14.09it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  49% 672/1362 [00:47<00:48, 14.13it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating:  92% 98/107 [00:05<00:00, 24.25it/s]\u001b[A\n",
            "Epoch 3:  50% 676/1362 [00:47<00:48, 14.16it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Epoch 3:  50% 680/1362 [00:47<00:48, 14.20it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.850, valid/ppl=346.0]\n",
            "Validating: 100% 107/107 [00:05<00:00, 18.26it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 345.6642761230469\n",
            "lr = tensor(4.2315e-05, device='cuda:0')\n",
            "train/loss = tensor(5.8104, device='cuda:0')\n",
            "train/lr = tensor(4.2315e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.7668, device='cuda:0')\n",
            "valid/ppl = tensor(319.5165, device='cuda:0')\n",
            "\n",
            "Epoch 3:  50% 682/1362 [00:48<00:47, 14.17it/s, loss=5.57, train/ppl=100.0, lr=4.23e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "                                                 \u001b[ASaving a model at step=1004 in epoch=3...\n",
            "Epoch 3:  92% 1256/1362 [01:35<00:08, 13.10it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  93% 1260/1362 [01:36<00:07, 13.07it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating:   4% 4/107 [00:00<00:12,  8.19it/s]\u001b[A\n",
            "Epoch 3:  93% 1264/1362 [01:36<00:07, 13.09it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  93% 1268/1362 [01:36<00:07, 13.11it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  93% 1272/1362 [01:36<00:06, 13.13it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating:  15% 16/107 [00:01<00:04, 20.15it/s]\u001b[A\n",
            "Epoch 3:  94% 1276/1362 [01:37<00:06, 13.15it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  94% 1280/1362 [01:37<00:06, 13.17it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  94% 1284/1362 [01:37<00:05, 13.19it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating:  26% 28/107 [00:01<00:03, 22.82it/s]\u001b[A\n",
            "Epoch 3:  95% 1288/1362 [01:37<00:05, 13.20it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  95% 1292/1362 [01:37<00:05, 13.22it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  95% 1296/1362 [01:37<00:04, 13.23it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating:  37% 40/107 [00:02<00:03, 21.23it/s]\u001b[A\n",
            "Epoch 3:  95% 1300/1362 [01:38<00:04, 13.25it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  96% 1304/1362 [01:38<00:04, 13.26it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  96% 1308/1362 [01:38<00:04, 13.28it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating:  49% 52/107 [00:02<00:02, 22.68it/s]\u001b[A\n",
            "Epoch 3:  96% 1312/1362 [01:38<00:03, 13.30it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  97% 1316/1362 [01:38<00:03, 13.32it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  97% 1320/1362 [01:38<00:03, 13.34it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating:  60% 64/107 [00:03<00:01, 25.10it/s]\u001b[A\n",
            "Epoch 3:  97% 1324/1362 [01:39<00:02, 13.36it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  98% 1328/1362 [01:39<00:02, 13.38it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  98% 1332/1362 [01:39<00:02, 13.40it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating:  71% 76/107 [00:03<00:01, 24.91it/s]\u001b[A\n",
            "Epoch 3:  98% 1336/1362 [01:39<00:01, 13.42it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  98% 1340/1362 [01:39<00:01, 13.44it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  99% 1344/1362 [01:39<00:01, 13.46it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating:  82% 88/107 [00:04<00:00, 25.52it/s]\u001b[A\n",
            "Epoch 3:  99% 1348/1362 [01:40<00:01, 13.47it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3:  99% 1352/1362 [01:40<00:00, 13.49it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Epoch 3: 100% 1356/1362 [01:40<00:00, 13.51it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating:  93% 100/107 [00:04<00:00, 24.63it/s]\u001b[A\n",
            "Epoch 3: 100% 1360/1362 [01:40<00:00, 13.53it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.770, valid/ppl=320.0]\n",
            "Validating:  99% 106/107 [00:04<00:00, 25.14it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 319.5165100097656\n",
            "lr = tensor(3.9070e-05, device='cuda:0')\n",
            "train/loss = tensor(5.9181, device='cuda:0')\n",
            "train/lr = tensor(3.9070e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.6900, device='cuda:0')\n",
            "valid/ppl = tensor(295.8953, device='cuda:0')\n",
            "\n",
            "Epoch 3: 100% 1362/1362 [01:40<00:00, 13.50it/s, loss=5.62, train/ppl=100.0, lr=3.91e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "                                                 \u001b[ASaving a model at step=1147 in epoch=3...\n",
            "Epoch 4:  42% 574/1362 [00:42<00:58, 13.37it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  42% 576/1362 [00:43<00:59, 13.28it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  43% 580/1362 [00:43<00:58, 13.31it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  43% 584/1362 [00:43<00:58, 13.36it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Validating:   9% 10/107 [00:00<00:05, 16.59it/s]\u001b[A\n",
            "Epoch 4:  43% 588/1362 [00:43<00:57, 13.40it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  43% 592/1362 [00:44<00:57, 13.44it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  44% 596/1362 [00:44<00:56, 13.49it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Validating:  21% 22/107 [00:01<00:03, 22.28it/s]\u001b[A\n",
            "Epoch 4:  44% 600/1362 [00:44<00:56, 13.52it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  44% 604/1362 [00:44<00:55, 13.56it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  45% 608/1362 [00:44<00:55, 13.60it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Validating:  32% 34/107 [00:01<00:03, 23.85it/s]\u001b[A\n",
            "Epoch 4:  45% 612/1362 [00:44<00:55, 13.63it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  45% 616/1362 [00:45<00:54, 13.66it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  46% 620/1362 [00:45<00:54, 13.69it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Validating:  43% 46/107 [00:02<00:02, 21.28it/s]\u001b[A\n",
            "Epoch 4:  46% 624/1362 [00:45<00:53, 13.73it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  46% 628/1362 [00:45<00:53, 13.76it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  46% 632/1362 [00:45<00:52, 13.81it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Validating:  54% 58/107 [00:02<00:01, 24.73it/s]\u001b[A\n",
            "Epoch 4:  47% 636/1362 [00:45<00:52, 13.84it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  47% 640/1362 [00:46<00:51, 13.88it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  47% 644/1362 [00:46<00:51, 13.92it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Validating:  65% 70/107 [00:03<00:01, 24.73it/s]\u001b[A\n",
            "Epoch 4:  48% 648/1362 [00:46<00:51, 13.95it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  48% 652/1362 [00:46<00:50, 13.98it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  48% 656/1362 [00:46<00:50, 14.02it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Validating:  77% 82/107 [00:03<00:01, 22.69it/s]\u001b[A\n",
            "Epoch 4:  48% 660/1362 [00:46<00:49, 14.04it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  49% 664/1362 [00:47<00:49, 14.07it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  49% 668/1362 [00:47<00:49, 14.11it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Validating:  88% 94/107 [00:04<00:00, 22.84it/s]\u001b[A\n",
            "Epoch 4:  49% 672/1362 [00:47<00:48, 14.14it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  50% 676/1362 [00:47<00:48, 14.18it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Epoch 4:  50% 680/1362 [00:47<00:47, 14.22it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.690, valid/ppl=296.0]\n",
            "Validating:  99% 106/107 [00:04<00:00, 24.44it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 295.89532470703125\n",
            "lr = tensor(3.5801e-05, device='cuda:0')\n",
            "train/loss = tensor(5.2995, device='cuda:0')\n",
            "train/lr = tensor(3.5801e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.6301, device='cuda:0')\n",
            "valid/ppl = tensor(278.6797, device='cuda:0')\n",
            "\n",
            "Epoch 4:  50% 682/1362 [00:48<00:48, 14.14it/s, loss=5.47, train/ppl=100.0, lr=3.58e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "                                                 \u001b[ASaving a model at step=1291 in epoch=4...\n",
            "Epoch 4:  92% 1256/1362 [01:36<00:08, 13.06it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:   1% 1/107 [00:00<01:13,  1.45it/s]\u001b[A\n",
            "Epoch 4:  93% 1260/1362 [01:36<00:07, 12.99it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  93% 1264/1362 [01:37<00:07, 13.01it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  93% 1268/1362 [01:37<00:07, 13.03it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating:  11% 12/107 [00:01<00:06, 14.70it/s]\u001b[A\n",
            "Epoch 4:  93% 1272/1362 [01:37<00:06, 13.04it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  94% 1276/1362 [01:37<00:06, 13.06it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  94% 1280/1362 [01:37<00:06, 13.07it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating:  22% 24/107 [00:01<00:04, 19.38it/s]\u001b[A\n",
            "Epoch 4:  94% 1284/1362 [01:38<00:05, 13.09it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  95% 1288/1362 [01:38<00:05, 13.10it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  95% 1292/1362 [01:38<00:05, 13.11it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating:  34% 36/107 [00:02<00:03, 18.14it/s]\u001b[A\n",
            "Epoch 4:  95% 1296/1362 [01:38<00:05, 13.12it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating:  38% 41/107 [00:02<00:03, 18.74it/s]\u001b[A\n",
            "Epoch 4:  95% 1300/1362 [01:38<00:04, 13.14it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating:  42% 45/107 [00:02<00:03, 18.59it/s]\u001b[A\n",
            "Epoch 4:  96% 1304/1362 [01:39<00:04, 13.15it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  96% 1308/1362 [01:39<00:04, 13.16it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  96% 1312/1362 [01:39<00:03, 13.18it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating:  52% 56/107 [00:03<00:02, 21.40it/s]\u001b[A\n",
            "Epoch 4:  97% 1316/1362 [01:39<00:03, 13.20it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  97% 1320/1362 [01:39<00:03, 13.21it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  97% 1324/1362 [01:40<00:02, 13.23it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating:  64% 68/107 [00:03<00:01, 22.03it/s]\u001b[A\n",
            "Epoch 4:  98% 1328/1362 [01:40<00:02, 13.24it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  98% 1332/1362 [01:40<00:02, 13.26it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  98% 1336/1362 [01:40<00:01, 13.28it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating:  75% 80/107 [00:04<00:01, 25.37it/s]\u001b[A\n",
            "Epoch 4:  98% 1340/1362 [01:40<00:01, 13.30it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  99% 1344/1362 [01:40<00:01, 13.32it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4:  99% 1348/1362 [01:41<00:01, 13.34it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating:  86% 92/107 [00:04<00:00, 25.71it/s]\u001b[A\n",
            "Epoch 4:  99% 1352/1362 [01:41<00:00, 13.36it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4: 100% 1356/1362 [01:41<00:00, 13.38it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Epoch 4: 100% 1360/1362 [01:41<00:00, 13.40it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.630, valid/ppl=279.0]\n",
            "Validating:  97% 104/107 [00:05<00:00, 25.38it/s]\u001b[A\n",
            "Validating: 100% 107/107 [00:05<00:00, 18.21it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 278.6796875\n",
            "lr = tensor(3.2555e-05, device='cuda:0')\n",
            "train/loss = tensor(5.0486, device='cuda:0')\n",
            "train/lr = tensor(3.2555e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.5836, device='cuda:0')\n",
            "valid/ppl = tensor(266.0255, device='cuda:0')\n",
            "\n",
            "Epoch 4: 100% 1362/1362 [01:41<00:00, 13.37it/s, loss=5.43, train/ppl=100.0, lr=3.26e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "                                                 \u001b[ASaving a model at step=1434 in epoch=4...\n",
            "Epoch 5:  42% 574/1362 [00:43<00:59, 13.33it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  42% 576/1362 [00:43<00:59, 13.23it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  43% 580/1362 [00:43<00:58, 13.27it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  43% 584/1362 [00:43<00:58, 13.31it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Validating:   9% 10/107 [00:00<00:05, 16.67it/s]\u001b[A\n",
            "Epoch 5:  43% 588/1362 [00:44<00:57, 13.36it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  43% 592/1362 [00:44<00:57, 13.40it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  44% 596/1362 [00:44<00:56, 13.45it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Validating:  21% 22/107 [00:01<00:03, 22.83it/s]\u001b[A\n",
            "Epoch 5:  44% 600/1362 [00:44<00:56, 13.48it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  44% 604/1362 [00:44<00:56, 13.52it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  45% 608/1362 [00:44<00:55, 13.55it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Validating:  32% 34/107 [00:01<00:03, 22.61it/s]\u001b[A\n",
            "Epoch 5:  45% 612/1362 [00:45<00:55, 13.58it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  45% 616/1362 [00:45<00:54, 13.61it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  46% 620/1362 [00:45<00:54, 13.64it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Validating:  43% 46/107 [00:02<00:02, 20.82it/s]\u001b[A\n",
            "Epoch 5:  46% 624/1362 [00:45<00:53, 13.68it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  46% 628/1362 [00:45<00:53, 13.72it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  46% 632/1362 [00:45<00:53, 13.76it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Validating:  54% 58/107 [00:02<00:01, 24.77it/s]\u001b[A\n",
            "Epoch 5:  47% 636/1362 [00:46<00:52, 13.80it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  47% 640/1362 [00:46<00:52, 13.84it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  47% 644/1362 [00:46<00:51, 13.88it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Validating:  65% 70/107 [00:03<00:01, 24.99it/s]\u001b[A\n",
            "Epoch 5:  48% 648/1362 [00:46<00:51, 13.91it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  48% 652/1362 [00:46<00:50, 13.95it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  48% 656/1362 [00:46<00:50, 14.00it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Validating:  77% 82/107 [00:03<00:00, 26.96it/s]\u001b[A\n",
            "Epoch 5:  48% 660/1362 [00:47<00:50, 14.03it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  49% 664/1362 [00:47<00:49, 14.07it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  49% 668/1362 [00:47<00:49, 14.11it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Validating:  88% 94/107 [00:04<00:00, 25.30it/s]\u001b[A\n",
            "Epoch 5:  49% 672/1362 [00:47<00:48, 14.14it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  50% 676/1362 [00:47<00:48, 14.18it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Epoch 5:  50% 680/1362 [00:47<00:47, 14.22it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.580, valid/ppl=266.0]\n",
            "Validating:  99% 106/107 [00:04<00:00, 25.15it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 266.02545166015625\n",
            "lr = tensor(2.9287e-05, device='cuda:0')\n",
            "train/loss = tensor(5.3713, device='cuda:0')\n",
            "train/lr = tensor(2.9287e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.5394, device='cuda:0')\n",
            "valid/ppl = tensor(254.5324, device='cuda:0')\n",
            "\n",
            "Epoch 5:  50% 682/1362 [00:48<00:47, 14.19it/s, loss=5.28, train/ppl=100.0, lr=2.93e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "                                                 \u001b[ASaving a model at step=1578 in epoch=5...\n",
            "Epoch 5:  92% 1256/1362 [01:35<00:08, 13.15it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:   1% 1/107 [00:00<00:44,  2.39it/s]\u001b[A\n",
            "Epoch 5:  93% 1260/1362 [01:36<00:07, 13.12it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  93% 1264/1362 [01:36<00:07, 13.14it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  93% 1268/1362 [01:36<00:07, 13.16it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Validating:  11% 12/107 [00:00<00:04, 19.30it/s]\u001b[A\n",
            "Epoch 5:  93% 1272/1362 [01:36<00:06, 13.18it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  94% 1276/1362 [01:36<00:06, 13.20it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  94% 1280/1362 [01:36<00:06, 13.22it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Validating:  22% 24/107 [00:01<00:03, 23.50it/s]\u001b[A\n",
            "Epoch 5:  94% 1284/1362 [01:36<00:05, 13.24it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  95% 1288/1362 [01:37<00:05, 13.26it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  95% 1292/1362 [01:37<00:05, 13.27it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Validating:  34% 36/107 [00:01<00:03, 21.20it/s]\u001b[A\n",
            "Epoch 5:  95% 1296/1362 [01:37<00:04, 13.29it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  95% 1300/1362 [01:37<00:04, 13.30it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  96% 1304/1362 [01:37<00:04, 13.32it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Validating:  45% 48/107 [00:02<00:02, 21.94it/s]\u001b[A\n",
            "Epoch 5:  96% 1308/1362 [01:38<00:04, 13.34it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  96% 1312/1362 [01:38<00:03, 13.36it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  97% 1316/1362 [01:38<00:03, 13.38it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Validating:  56% 60/107 [00:02<00:01, 24.17it/s]\u001b[A\n",
            "Epoch 5:  97% 1320/1362 [01:38<00:03, 13.40it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  97% 1324/1362 [01:38<00:02, 13.42it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  98% 1328/1362 [01:38<00:02, 13.43it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Validating:  67% 72/107 [00:03<00:01, 24.65it/s]\u001b[A\n",
            "Epoch 5:  98% 1332/1362 [01:39<00:02, 13.45it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  98% 1336/1362 [01:39<00:01, 13.47it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  98% 1340/1362 [01:39<00:01, 13.49it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Validating:  79% 84/107 [00:03<00:00, 26.32it/s]\u001b[A\n",
            "Epoch 5:  99% 1344/1362 [01:39<00:01, 13.51it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  99% 1348/1362 [01:39<00:01, 13.53it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5:  99% 1352/1362 [01:39<00:00, 13.55it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Validating:  90% 96/107 [00:04<00:00, 24.28it/s]\u001b[A\n",
            "Epoch 5: 100% 1356/1362 [01:39<00:00, 13.56it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Epoch 5: 100% 1360/1362 [01:40<00:00, 13.58it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.540, valid/ppl=255.0]\n",
            "Validating:  98% 105/107 [00:04<00:00, 24.57it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 254.5324249267578\n",
            "lr = tensor(2.6041e-05, device='cuda:0')\n",
            "train/loss = tensor(4.7319, device='cuda:0')\n",
            "train/lr = tensor(2.6041e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.5064, device='cuda:0')\n",
            "valid/ppl = tensor(246.2661, device='cuda:0')\n",
            "\n",
            "Epoch 5: 100% 1362/1362 [01:40<00:00, 13.54it/s, loss=5.25, train/ppl=100.0, lr=2.6e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "                                                 \u001b[ASaving a model at step=1721 in epoch=5...\n",
            "Epoch 6:  42% 574/1362 [00:42<00:58, 13.38it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  42% 576/1362 [00:43<00:59, 13.22it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  43% 580/1362 [00:43<00:59, 13.25it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating:   6% 6/107 [00:00<00:11,  9.13it/s]\u001b[A\n",
            "Epoch 6:  43% 584/1362 [00:43<00:58, 13.29it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  43% 588/1362 [00:44<00:58, 13.32it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  43% 592/1362 [00:44<00:57, 13.36it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating:  17% 18/107 [00:01<00:04, 18.00it/s]\u001b[A\n",
            "Epoch 6:  44% 596/1362 [00:44<00:57, 13.39it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  44% 600/1362 [00:44<00:56, 13.43it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  44% 604/1362 [00:44<00:56, 13.46it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating:  28% 30/107 [00:02<00:03, 20.77it/s]\u001b[A\n",
            "Epoch 6:  45% 608/1362 [00:45<00:55, 13.49it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  45% 612/1362 [00:45<00:55, 13.51it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  45% 616/1362 [00:45<00:55, 13.54it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating:  39% 42/107 [00:02<00:03, 19.34it/s]\u001b[A\n",
            "Epoch 6:  46% 620/1362 [00:45<00:54, 13.56it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating:  43% 46/107 [00:02<00:03, 18.95it/s]\u001b[A\n",
            "Epoch 6:  46% 624/1362 [00:45<00:54, 13.59it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  46% 628/1362 [00:46<00:53, 13.62it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating:  50% 54/107 [00:03<00:02, 20.79it/s]\u001b[A\n",
            "Epoch 6:  46% 632/1362 [00:46<00:53, 13.66it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  47% 636/1362 [00:46<00:53, 13.69it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  47% 640/1362 [00:46<00:52, 13.73it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating:  62% 66/107 [00:03<00:01, 22.43it/s]\u001b[A\n",
            "Epoch 6:  47% 644/1362 [00:46<00:52, 13.76it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  48% 648/1362 [00:46<00:51, 13.79it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  48% 652/1362 [00:47<00:51, 13.82it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating:  73% 78/107 [00:04<00:01, 22.72it/s]\u001b[A\n",
            "Epoch 6:  48% 656/1362 [00:47<00:50, 13.86it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  48% 660/1362 [00:47<00:50, 13.88it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  49% 664/1362 [00:47<00:50, 13.92it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating:  84% 90/107 [00:04<00:00, 22.32it/s]\u001b[A\n",
            "Epoch 6:  49% 668/1362 [00:47<00:49, 13.95it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  49% 672/1362 [00:48<00:49, 13.99it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Epoch 6:  50% 676/1362 [00:48<00:48, 14.03it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]\n",
            "Validating:  95% 102/107 [00:05<00:00, 24.16it/s]\u001b[A\n",
            "Epoch 6:  50% 680/1362 [00:48<00:48, 14.06it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.510, valid/ppl=246.0]***** Validation results *****\n",
            "early stop 0/5 - best = 246.2660675048828\n",
            "lr = tensor(2.2772e-05, device='cuda:0')\n",
            "train/loss = tensor(5.1146, device='cuda:0')\n",
            "train/lr = tensor(2.2772e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.4951, device='cuda:0')\n",
            "valid/ppl = tensor(243.4873, device='cuda:0')\n",
            "\n",
            "Epoch 6:  50% 682/1362 [00:48<00:48, 14.03it/s, loss=5.13, train/ppl=100.0, lr=2.28e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "                                                 \u001b[ASaving a model at step=1865 in epoch=6...\n",
            "Epoch 6:  92% 1256/1362 [01:36<00:08, 13.06it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  93% 1260/1362 [01:36<00:07, 13.01it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating:   4% 4/107 [00:00<00:14,  6.94it/s]\u001b[A\n",
            "Epoch 6:  93% 1264/1362 [01:37<00:07, 13.03it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  93% 1268/1362 [01:37<00:07, 13.05it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  93% 1272/1362 [01:37<00:06, 13.07it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating:  15% 16/107 [00:01<00:04, 19.85it/s]\u001b[A\n",
            "Epoch 6:  94% 1276/1362 [01:37<00:06, 13.09it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  94% 1280/1362 [01:37<00:06, 13.11it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  94% 1284/1362 [01:37<00:05, 13.13it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating:  26% 28/107 [00:01<00:03, 22.83it/s]\u001b[A\n",
            "Epoch 6:  95% 1288/1362 [01:37<00:05, 13.14it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  95% 1292/1362 [01:38<00:05, 13.16it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  95% 1296/1362 [01:38<00:05, 13.17it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating:  37% 40/107 [00:02<00:03, 20.97it/s]\u001b[A\n",
            "Epoch 6:  95% 1300/1362 [01:38<00:04, 13.19it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  96% 1304/1362 [01:38<00:04, 13.20it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  96% 1308/1362 [01:38<00:04, 13.22it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating:  49% 52/107 [00:02<00:02, 22.60it/s]\u001b[A\n",
            "Epoch 6:  96% 1312/1362 [01:39<00:03, 13.24it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  97% 1316/1362 [01:39<00:03, 13.26it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  97% 1320/1362 [01:39<00:03, 13.28it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating:  60% 64/107 [00:03<00:01, 24.87it/s]\u001b[A\n",
            "Epoch 6:  97% 1324/1362 [01:39<00:02, 13.30it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  98% 1328/1362 [01:39<00:02, 13.32it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  98% 1332/1362 [01:39<00:02, 13.34it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating:  71% 76/107 [00:03<00:01, 25.11it/s]\u001b[A\n",
            "Epoch 6:  98% 1336/1362 [01:40<00:01, 13.36it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  98% 1340/1362 [01:40<00:01, 13.38it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  99% 1344/1362 [01:40<00:01, 13.40it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating:  82% 88/107 [00:04<00:00, 25.85it/s]\u001b[A\n",
            "Epoch 6:  99% 1348/1362 [01:40<00:01, 13.41it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6:  99% 1352/1362 [01:40<00:00, 13.43it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Epoch 6: 100% 1356/1362 [01:40<00:00, 13.45it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating:  93% 100/107 [00:04<00:00, 24.86it/s]\u001b[A\n",
            "Epoch 6: 100% 1360/1362 [01:40<00:00, 13.47it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.500, valid/ppl=243.0]\n",
            "Validating:  99% 106/107 [00:04<00:00, 25.11it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 243.48728942871094\n",
            "lr = tensor(1.9527e-05, device='cuda:0')\n",
            "train/loss = tensor(4.8398, device='cuda:0')\n",
            "train/lr = tensor(1.9527e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.4486, device='cuda:0')\n",
            "valid/ppl = tensor(232.4273, device='cuda:0')\n",
            "\n",
            "Epoch 6: 100% 1362/1362 [01:41<00:00, 13.44it/s, loss=5.28, train/ppl=100.0, lr=1.95e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "                                                 \u001b[ASaving a model at step=2008 in epoch=6...\n",
            "Epoch 7:  42% 574/1362 [00:42<00:59, 13.35it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  42% 576/1362 [00:43<00:59, 13.27it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  43% 580/1362 [00:43<00:58, 13.29it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Validating:   6% 6/107 [00:00<00:08, 11.71it/s]\u001b[A\n",
            "Epoch 7:  43% 584/1362 [00:43<00:58, 13.34it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  43% 588/1362 [00:43<00:57, 13.38it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  43% 592/1362 [00:44<00:57, 13.42it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Validating:  17% 18/107 [00:01<00:04, 21.93it/s]\u001b[A\n",
            "Epoch 7:  44% 596/1362 [00:44<00:56, 13.47it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  44% 600/1362 [00:44<00:56, 13.51it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  44% 604/1362 [00:44<00:55, 13.55it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Validating:  28% 30/107 [00:01<00:03, 23.65it/s]\u001b[A\n",
            "Epoch 7:  45% 608/1362 [00:44<00:55, 13.59it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  45% 612/1362 [00:44<00:55, 13.61it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  45% 616/1362 [00:45<00:54, 13.64it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Validating:  39% 42/107 [00:02<00:02, 21.73it/s]\u001b[A\n",
            "Epoch 7:  46% 620/1362 [00:45<00:54, 13.68it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  46% 624/1362 [00:45<00:53, 13.71it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  46% 628/1362 [00:45<00:53, 13.74it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Validating:  50% 54/107 [00:02<00:02, 21.34it/s]\u001b[A\n",
            "Epoch 7:  46% 632/1362 [00:45<00:52, 13.78it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  47% 636/1362 [00:46<00:52, 13.81it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  47% 640/1362 [00:46<00:52, 13.85it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Validating:  62% 66/107 [00:03<00:01, 24.19it/s]\u001b[A\n",
            "Epoch 7:  47% 644/1362 [00:46<00:51, 13.89it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  48% 648/1362 [00:46<00:51, 13.93it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  48% 652/1362 [00:46<00:50, 13.97it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Validating:  73% 78/107 [00:03<00:01, 25.88it/s]\u001b[A\n",
            "Epoch 7:  48% 656/1362 [00:46<00:50, 14.02it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  48% 660/1362 [00:46<00:49, 14.05it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  49% 664/1362 [00:47<00:49, 14.09it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Validating:  84% 90/107 [00:04<00:00, 25.13it/s]\u001b[A\n",
            "Epoch 7:  49% 668/1362 [00:47<00:49, 14.13it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  49% 672/1362 [00:47<00:48, 14.16it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Epoch 7:  50% 676/1362 [00:47<00:48, 14.20it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]\n",
            "Validating:  95% 102/107 [00:04<00:00, 25.23it/s]\u001b[A\n",
            "Epoch 7:  50% 680/1362 [00:47<00:47, 14.24it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.450, valid/ppl=232.0]***** Validation results *****\n",
            "early stop 0/5 - best = 232.42727661132812\n",
            "lr = tensor(1.6258e-05, device='cuda:0')\n",
            "train/loss = tensor(5.2658, device='cuda:0')\n",
            "train/lr = tensor(1.6258e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.4251, device='cuda:0')\n",
            "valid/ppl = tensor(227.0348, device='cuda:0')\n",
            "\n",
            "Epoch 7:  50% 682/1362 [00:48<00:47, 14.20it/s, loss=5.07, train/ppl=100.0, lr=1.63e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "                                                 \u001b[ASaving a model at step=2152 in epoch=7...\n",
            "Epoch 7:  92% 1256/1362 [01:35<00:08, 13.14it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:   1% 1/107 [00:00<00:45,  2.32it/s]\u001b[A\n",
            "Epoch 7:  93% 1260/1362 [01:36<00:07, 13.10it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  93% 1264/1362 [01:36<00:07, 13.12it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  93% 1268/1362 [01:36<00:07, 13.14it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Validating:  11% 12/107 [00:00<00:05, 17.75it/s]\u001b[A\n",
            "Epoch 7:  93% 1272/1362 [01:36<00:06, 13.15it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  94% 1276/1362 [01:36<00:06, 13.17it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  94% 1280/1362 [01:37<00:06, 13.19it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Validating:  22% 24/107 [00:01<00:04, 20.28it/s]\u001b[A\n",
            "Epoch 7:  94% 1284/1362 [01:37<00:05, 13.20it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  95% 1288/1362 [01:37<00:05, 13.22it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  95% 1292/1362 [01:37<00:05, 13.23it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Validating:  34% 36/107 [00:02<00:03, 19.00it/s]\u001b[A\n",
            "Epoch 7:  95% 1296/1362 [01:37<00:04, 13.24it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  95% 1300/1362 [01:38<00:04, 13.26it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Validating:  41% 44/107 [00:02<00:03, 20.47it/s]\u001b[A\n",
            "Epoch 7:  96% 1304/1362 [01:38<00:04, 13.27it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  96% 1308/1362 [01:38<00:04, 13.29it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  96% 1312/1362 [01:38<00:03, 13.30it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Validating:  52% 56/107 [00:03<00:02, 21.47it/s]\u001b[A\n",
            "Epoch 7:  97% 1316/1362 [01:38<00:03, 13.32it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  97% 1320/1362 [01:38<00:03, 13.34it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  97% 1324/1362 [01:39<00:02, 13.35it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Validating:  64% 68/107 [00:03<00:01, 21.93it/s]\u001b[A\n",
            "Epoch 7:  98% 1328/1362 [01:39<00:02, 13.37it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  98% 1332/1362 [01:39<00:02, 13.38it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  98% 1336/1362 [01:39<00:01, 13.40it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Validating:  75% 80/107 [00:04<00:01, 23.66it/s]\u001b[A\n",
            "Epoch 7:  98% 1340/1362 [01:39<00:01, 13.42it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  99% 1344/1362 [01:40<00:01, 13.44it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7:  99% 1348/1362 [01:40<00:01, 13.45it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Validating:  86% 92/107 [00:04<00:00, 23.29it/s]\u001b[A\n",
            "Epoch 7:  99% 1352/1362 [01:40<00:00, 13.47it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7: 100% 1356/1362 [01:40<00:00, 13.49it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Epoch 7: 100% 1360/1362 [01:40<00:00, 13.51it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.430, valid/ppl=227.0]\n",
            "Validating:  97% 104/107 [00:05<00:00, 24.04it/s]\u001b[A\n",
            "Validating: 100% 107/107 [00:05<00:00, 14.83it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 227.03477478027344\n",
            "lr = tensor(1.3012e-05, device='cuda:0')\n",
            "train/loss = tensor(6.1957, device='cuda:0')\n",
            "train/lr = tensor(1.3012e-05, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.4006, device='cuda:0')\n",
            "valid/ppl = tensor(221.5494, device='cuda:0')\n",
            "\n",
            "Epoch 7: 100% 1362/1362 [01:41<00:00, 13.47it/s, loss=5.15, train/ppl=100.0, lr=1.3e-5, valid/loss=5.400, valid/ppl=222.0]\n",
            "                                                 \u001b[ASaving a model at step=2295 in epoch=7...\n",
            "Epoch 8:  42% 574/1362 [00:42<00:58, 13.38it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  42% 576/1362 [00:43<00:59, 13.23it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  43% 580/1362 [00:43<00:58, 13.26it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Validating:   6% 6/107 [00:00<00:11,  9.11it/s]\u001b[A\n",
            "Epoch 8:  43% 584/1362 [00:43<00:58, 13.30it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  43% 588/1362 [00:44<00:58, 13.34it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  43% 592/1362 [00:44<00:57, 13.38it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Validating:  17% 18/107 [00:01<00:04, 19.73it/s]\u001b[A\n",
            "Epoch 8:  44% 596/1362 [00:44<00:57, 13.42it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  44% 600/1362 [00:44<00:56, 13.45it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  44% 604/1362 [00:44<00:56, 13.48it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Validating:  28% 30/107 [00:01<00:03, 21.80it/s]\u001b[A\n",
            "Epoch 8:  45% 608/1362 [00:44<00:55, 13.52it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  45% 612/1362 [00:45<00:55, 13.55it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  45% 616/1362 [00:45<00:54, 13.58it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Validating:  39% 42/107 [00:02<00:03, 21.61it/s]\u001b[A\n",
            "Epoch 8:  46% 620/1362 [00:45<00:54, 13.61it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  46% 624/1362 [00:45<00:54, 13.65it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  46% 628/1362 [00:45<00:53, 13.69it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Validating:  50% 54/107 [00:03<00:02, 22.82it/s]\u001b[A\n",
            "Epoch 8:  46% 632/1362 [00:46<00:53, 13.73it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  47% 636/1362 [00:46<00:52, 13.77it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  47% 640/1362 [00:46<00:52, 13.81it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Validating:  62% 66/107 [00:03<00:01, 25.13it/s]\u001b[A\n",
            "Epoch 8:  47% 644/1362 [00:46<00:51, 13.85it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  48% 648/1362 [00:46<00:51, 13.89it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  48% 652/1362 [00:46<00:50, 13.93it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  48% 656/1362 [00:46<00:50, 13.97it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Validating:  77% 82/107 [00:04<00:00, 27.35it/s]\u001b[A\n",
            "Epoch 8:  48% 660/1362 [00:47<00:50, 14.01it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  49% 664/1362 [00:47<00:49, 14.05it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  49% 668/1362 [00:47<00:49, 14.09it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Validating:  88% 94/107 [00:04<00:00, 25.51it/s]\u001b[A\n",
            "Epoch 8:  49% 672/1362 [00:47<00:48, 14.12it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  50% 676/1362 [00:47<00:48, 14.16it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Epoch 8:  50% 680/1362 [00:47<00:48, 14.19it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=222.0]\n",
            "Validating:  99% 106/107 [00:05<00:00, 25.31it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 221.5494384765625\n",
            "lr = tensor(9.7438e-06, device='cuda:0')\n",
            "train/loss = tensor(5.3512, device='cuda:0')\n",
            "train/lr = tensor(9.7438e-06, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.3983, device='cuda:0')\n",
            "valid/ppl = tensor(221.0390, device='cuda:0')\n",
            "\n",
            "Epoch 8:  50% 682/1362 [00:48<00:48, 14.16it/s, loss=5.14, train/ppl=100.0, lr=9.74e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "                                                 \u001b[ASaving a model at step=2439 in epoch=8...\n",
            "Epoch 8:  92% 1256/1362 [01:35<00:08, 13.12it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:   1% 1/107 [00:00<00:45,  2.32it/s]\u001b[A\n",
            "Epoch 8:  93% 1260/1362 [01:36<00:07, 13.08it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  93% 1264/1362 [01:36<00:07, 13.11it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  93% 1268/1362 [01:36<00:07, 13.13it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Validating:  11% 12/107 [00:00<00:04, 19.26it/s]\u001b[A\n",
            "Epoch 8:  93% 1272/1362 [01:36<00:06, 13.14it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  94% 1276/1362 [01:36<00:06, 13.17it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  94% 1280/1362 [01:37<00:06, 13.18it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Validating:  22% 24/107 [00:01<00:03, 23.00it/s]\u001b[A\n",
            "Epoch 8:  94% 1284/1362 [01:37<00:05, 13.20it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  95% 1288/1362 [01:37<00:05, 13.22it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  95% 1292/1362 [01:37<00:05, 13.23it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Validating:  34% 36/107 [00:01<00:03, 21.24it/s]\u001b[A\n",
            "Epoch 8:  95% 1296/1362 [01:37<00:04, 13.25it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  95% 1300/1362 [01:37<00:04, 13.27it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  96% 1304/1362 [01:38<00:04, 13.28it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Validating:  45% 48/107 [00:02<00:02, 21.87it/s]\u001b[A\n",
            "Epoch 8:  96% 1308/1362 [01:38<00:04, 13.30it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  96% 1312/1362 [01:38<00:03, 13.32it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  97% 1316/1362 [01:38<00:03, 13.34it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Validating:  56% 60/107 [00:02<00:01, 24.04it/s]\u001b[A\n",
            "Epoch 8:  97% 1320/1362 [01:38<00:03, 13.36it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  97% 1324/1362 [01:38<00:02, 13.38it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  98% 1328/1362 [01:39<00:02, 13.39it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Validating:  67% 72/107 [00:03<00:01, 24.27it/s]\u001b[A\n",
            "Epoch 8:  98% 1332/1362 [01:39<00:02, 13.41it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  98% 1336/1362 [01:39<00:01, 13.43it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  98% 1340/1362 [01:39<00:01, 13.45it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Validating:  79% 84/107 [00:03<00:00, 26.34it/s]\u001b[A\n",
            "Epoch 8:  99% 1344/1362 [01:39<00:01, 13.47it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  99% 1348/1362 [01:39<00:01, 13.49it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8:  99% 1352/1362 [01:40<00:00, 13.51it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Validating:  90% 96/107 [00:04<00:00, 24.51it/s]\u001b[A\n",
            "Epoch 8: 100% 1356/1362 [01:40<00:00, 13.53it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Epoch 8: 100% 1360/1362 [01:40<00:00, 13.55it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.400, valid/ppl=221.0]\n",
            "Validating:  98% 105/107 [00:04<00:00, 25.23it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 221.03903198242188\n",
            "lr = tensor(6.4980e-06, device='cuda:0')\n",
            "train/loss = tensor(4.8464, device='cuda:0')\n",
            "train/lr = tensor(6.4980e-06, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.3916, device='cuda:0')\n",
            "valid/ppl = tensor(219.5578, device='cuda:0')\n",
            "\n",
            "Epoch 8: 100% 1362/1362 [01:40<00:00, 13.52it/s, loss=5.05, train/ppl=100.0, lr=6.5e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "                                                 \u001b[ASaving a model at step=2582 in epoch=8...\n",
            "Epoch 9:  42% 574/1362 [00:42<00:58, 13.37it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  42% 576/1362 [00:43<00:59, 13.28it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  43% 580/1362 [00:43<00:58, 13.32it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Validating:   6% 6/107 [00:00<00:08, 11.77it/s]\u001b[A\n",
            "Epoch 9:  43% 584/1362 [00:43<00:58, 13.36it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  43% 588/1362 [00:43<00:57, 13.40it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  43% 592/1362 [00:44<00:57, 13.45it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Validating:  17% 18/107 [00:01<00:04, 21.68it/s]\u001b[A\n",
            "Epoch 9:  44% 596/1362 [00:44<00:56, 13.49it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  44% 600/1362 [00:44<00:56, 13.53it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  44% 604/1362 [00:44<00:55, 13.57it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Validating:  28% 30/107 [00:01<00:03, 24.09it/s]\u001b[A\n",
            "Epoch 9:  45% 608/1362 [00:44<00:55, 13.61it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  45% 612/1362 [00:44<00:55, 13.63it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  45% 616/1362 [00:45<00:54, 13.67it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Validating:  39% 42/107 [00:02<00:03, 21.07it/s]\u001b[A\n",
            "Epoch 9:  46% 620/1362 [00:45<00:54, 13.69it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  46% 624/1362 [00:45<00:53, 13.72it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  46% 628/1362 [00:45<00:53, 13.76it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Validating:  50% 54/107 [00:02<00:02, 21.46it/s]\u001b[A\n",
            "Epoch 9:  46% 632/1362 [00:45<00:52, 13.79it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  47% 636/1362 [00:46<00:52, 13.82it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  47% 640/1362 [00:46<00:52, 13.85it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Validating:  62% 66/107 [00:03<00:01, 22.50it/s]\u001b[A\n",
            "Epoch 9:  47% 644/1362 [00:46<00:51, 13.88it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  48% 648/1362 [00:46<00:51, 13.91it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  48% 652/1362 [00:46<00:50, 13.95it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Validating:  73% 78/107 [00:03<00:01, 22.36it/s]\u001b[A\n",
            "Epoch 9:  48% 656/1362 [00:46<00:50, 13.98it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  48% 660/1362 [00:47<00:50, 14.01it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  49% 664/1362 [00:47<00:49, 14.04it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Validating:  84% 90/107 [00:04<00:00, 22.23it/s]\u001b[A\n",
            "Epoch 9:  49% 668/1362 [00:47<00:49, 14.08it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  49% 672/1362 [00:47<00:48, 14.11it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Epoch 9:  50% 676/1362 [00:47<00:48, 14.15it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]\n",
            "Validating:  95% 102/107 [00:04<00:00, 23.86it/s]\u001b[A\n",
            "Epoch 9:  50% 680/1362 [00:47<00:48, 14.18it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.390, valid/ppl=220.0]***** Validation results *****\n",
            "early stop 0/5 - best = 219.55776977539062\n",
            "lr = tensor(3.2295e-06, device='cuda:0')\n",
            "train/loss = tensor(4.8359, device='cuda:0')\n",
            "train/lr = tensor(3.2295e-06, device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.3822, device='cuda:0')\n",
            "valid/ppl = tensor(217.5030, device='cuda:0')\n",
            "\n",
            "Epoch 9:  50% 682/1362 [00:48<00:48, 14.12it/s, loss=4.97, train/ppl=100.0, lr=3.23e-6, valid/loss=5.380, valid/ppl=218.0]\n",
            "                                                 \u001b[ASaving a model at step=2726 in epoch=9...\n",
            "Epoch 9:  92% 1256/1362 [01:36<00:08, 13.08it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:   1% 1/107 [00:00<01:09,  1.52it/s]\u001b[A\n",
            "Epoch 9:  93% 1260/1362 [01:36<00:07, 13.01it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  93% 1264/1362 [01:36<00:07, 13.03it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  93% 1268/1362 [01:37<00:07, 13.05it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Validating:  11% 12/107 [00:01<00:05, 15.97it/s]\u001b[A\n",
            "Epoch 9:  93% 1272/1362 [01:37<00:06, 13.06it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  94% 1276/1362 [01:37<00:06, 13.08it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  94% 1280/1362 [01:37<00:06, 13.10it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Validating:  22% 24/107 [00:01<00:04, 19.64it/s]\u001b[A\n",
            "Epoch 9:  94% 1284/1362 [01:37<00:05, 13.11it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  95% 1288/1362 [01:38<00:05, 13.13it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  95% 1292/1362 [01:38<00:05, 13.14it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Validating:  34% 36/107 [00:02<00:03, 18.12it/s]\u001b[A\n",
            "Epoch 9:  95% 1296/1362 [01:38<00:05, 13.15it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  95% 1300/1362 [01:38<00:04, 13.16it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Validating:  41% 44/107 [00:02<00:03, 19.63it/s]\u001b[A\n",
            "Epoch 9:  96% 1304/1362 [01:38<00:04, 13.17it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  96% 1308/1362 [01:39<00:04, 13.19it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Validating:  49% 52/107 [00:03<00:02, 20.23it/s]\u001b[A\n",
            "Epoch 9:  96% 1312/1362 [01:39<00:03, 13.21it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  97% 1316/1362 [01:39<00:03, 13.22it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  97% 1320/1362 [01:39<00:03, 13.24it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Validating:  60% 64/107 [00:03<00:01, 22.11it/s]\u001b[A\n",
            "Epoch 9:  97% 1324/1362 [01:39<00:02, 13.26it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  98% 1328/1362 [01:40<00:02, 13.27it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  98% 1332/1362 [01:40<00:02, 13.29it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Validating:  71% 76/107 [00:04<00:01, 22.85it/s]\u001b[A\n",
            "Epoch 9:  98% 1336/1362 [01:40<00:01, 13.31it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  98% 1340/1362 [01:40<00:01, 13.33it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  99% 1344/1362 [01:40<00:01, 13.35it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9:  99% 1348/1362 [01:40<00:01, 13.37it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Validating:  86% 92/107 [00:04<00:00, 25.51it/s]\u001b[A\n",
            "Epoch 9:  99% 1352/1362 [01:41<00:00, 13.38it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9: 100% 1356/1362 [01:41<00:00, 13.40it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9: 100% 1360/1362 [01:41<00:00, 13.42it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Validating:  97% 104/107 [00:05<00:00, 25.25it/s]\u001b[A\n",
            "Validating: 100% 107/107 [00:05<00:00, 17.72it/s]\u001b[A***** Validation results *****\n",
            "early stop 0/5 - best = 217.5030059814453\n",
            "lr = tensor(0., device='cuda:0')\n",
            "train/loss = tensor(5.7551, device='cuda:0')\n",
            "train/lr = tensor(0., device='cuda:0')\n",
            "train/ppl = tensor(100., device='cuda:0')\n",
            "valid/loss = tensor(5.3823, device='cuda:0')\n",
            "valid/ppl = tensor(217.5208, device='cuda:0')\n",
            "\n",
            "Epoch 9: 100% 1362/1362 [01:41<00:00, 13.40it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n",
            "Epoch 9: 100% 1362/1362 [01:41<00:00, 13.40it/s, loss=5.06, train/ppl=100.0, lr=0.000, valid/loss=5.380, valid/ppl=218.0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python /content/FaithDial/models/dialog.py --model_name_or_path ayushutkarsh/t3 \\\n",
        "  --do_train \\\n",
        "  --output_dir /content/\\\n",
        "  --fp16 \\\n",
        "  --train_batch_size 16 \\\n",
        "  --num_train_epochs 10 \\\n",
        "  --warmup_ratio 0.04 \\\n",
        "  --max_seq_length 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3whHS4VPMvXk",
        "outputId": "173f2c35-a8db-45cc-f31a-9c57ec68d41a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-10 02:32:02.254377: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-10 02:32:03.680706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/10/2023 02:32:06 - INFO - torch.distributed.nn.jit.instantiator - Created a temporary directory at /tmp/tmpfy2wot6e\n",
            "05/10/2023 02:32:06 - INFO - torch.distributed.nn.jit.instantiator - Writing /tmp/tmpfy2wot6e/_remote_module_non_scriptable.py\n",
            "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
            "05/10/2023 02:32:08 - WARNING - datasets.builder - No config specified, defaulting to: faith_dial_dataset/plain_text\n",
            "05/10/2023 02:32:08 - WARNING - datasets.builder - Reusing dataset faith_dial_dataset (/root/.cache/huggingface/datasets/McGill-NLP___faith_dial_dataset/plain_text/1.0.0/70568c8ab3bbc83b603bce58fa593ab27e7f0d0cde51034e1c2073ff3e14189a)\n",
            "05/10/2023 02:32:08 - WARNING - datasets.fingerprint - Parameter 'function'=<function ConversationalDataset._map.<locals>.<lambda> at 0x7f5e24c3a5f0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "100% 4/4 [00:01<00:00,  2.51ba/s]\n",
            "05/10/2023 02:32:10 - INFO - dataset - #conversational test examples loaded: 3539\n",
            "Global seed set to 42\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "05/10/2023 02:32:10 - WARNING - datasets.builder - No config specified, defaulting to: faith_dial_dataset/plain_text\n",
            "05/10/2023 02:32:10 - WARNING - datasets.builder - Reusing dataset faith_dial_dataset (/root/.cache/huggingface/datasets/McGill-NLP___faith_dial_dataset/plain_text/1.0.0/70568c8ab3bbc83b603bce58fa593ab27e7f0d0cde51034e1c2073ff3e14189a)\n",
            "100% 4/4 [00:01<00:00,  2.86ba/s]\n",
            "05/10/2023 02:32:12 - INFO - dataset - #conversational test examples loaded: 3539\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Missing logger folder: /content/best_model/valid_logs\n",
            "Testing: 100% 222/222 [00:18<00:00,  9.92it/s]--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test/loss': 0.1580345183610916, 'test/ppl': 1.1712065935134888}\n",
            "--------------------------------------------------------------------------------\n",
            "***** Test results *****\n",
            "test/loss = tensor(0.1580, device='cuda:0')\n",
            "\n",
            "test/ppl = tensor(1.1712, device='cuda:0')\n",
            "\n",
            "Testing: 100% 222/222 [00:18<00:00, 12.13it/s]\n"
          ]
        }
      ],
      "source": [
        "!python /content/FaithDial/models/dialog.py --model_name_or_path /content/best_model \\\n",
        "  --do_test \\\n",
        "  --eval_batch_size 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epTWmOjs7Jdu",
        "outputId": "a9ed3a27-40dc-4442-f108-097a87237ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-10 02:32:39.564186: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-10 02:32:41.101825: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/10/2023 02:32:42 - INFO - generate - `hparams.yaml` found from which parameter values (max_history, pad_to_multiple_of) will be loaded\n",
            "05/10/2023 02:32:42 - INFO - generate - Arguments: Namespace(dataset_path=None, model_name_or_path='/content/best_model', max_seq_length=512, output=None, max_history=1, batch_size=16, max_length=100, min_length=2, temperature=1.0, do_sample=True, repetition_penalty=1.0, top_k=0, top_p=0.6, num_return_sequences=1, exclude_knowledge=False, device='cuda', num_workers=10, control_tokens=('<entailed>',), do_generate=True, predict_dataset_path=None, do_train=False, do_eval=False, do_test=False, ctrl=False, max_negative_samples=0, pad_to_multiple_of=None)\n",
            "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
            "05/10/2023 02:32:48 - WARNING - datasets.builder - No config specified, defaulting to: faith_dial_dataset/plain_text\n",
            "05/10/2023 02:32:48 - WARNING - datasets.builder - Reusing dataset faith_dial_dataset (/root/.cache/huggingface/datasets/McGill-NLP___faith_dial_dataset/plain_text/1.0.0/70568c8ab3bbc83b603bce58fa593ab27e7f0d0cde51034e1c2073ff3e14189a)\n",
            "05/10/2023 02:32:48 - WARNING - datasets.fingerprint - Parameter 'function'=<function ConversationalDataset._map.<locals>.<lambda> at 0x7f8b768ca0e0> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "100% 4/4 [00:01<00:00,  3.05ba/s]\n",
            "100% 4/4 [00:01<00:00,  2.88ba/s]\n",
            "05/10/2023 02:32:50 - INFO - dataset - #conversational examples loaded for generation: 3539\n",
            "05/10/2023 02:32:50 - INFO - generate - Test dataset size: 3539\n",
            "05/10/2023 02:32:50 - INFO - generate - Results will be saved in `/content/best_model/outputs/generated_maxHist1_maxLen100_p0.6.jsonl`\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "  5% 12/222 [01:48<29:57,  8.56s/it]05/10/2023 02:34:47 - WARNING - generate - Empty generated response at 203: {'dialog_idx': 45, 'response': \"It's a travel destination due to its history, scenery, tropical climate, and cuisine.\", 'history': [\"Winter is the best time of year. The cold crisp air. The blanket of snow on the farm land. Don't you agree?\", \"I'm a bot and can't experience seasons, but I'm aware that it's the coldest of the seasons in temperate regions.\", \"I'm from Colorado so I know about snow. My city gets an average to 10-12 feet a year.\", 'Yes, winter is associated with freezing temps and with snow.', \"Yep. I bet they don't have snow in Puerto Rico, though.\", 'I wouldn\\'t know, but it\\'s located in the Caribbean Sea. Did you know its name means \"Rich Port\"?', \"No, that's interesting! What else do you know about Puerto Rico?\"], 'knowledge': \"Puerto Rico's history, tropical climate, natural scenery, traditional cuisine, and tax incentives make it a destination for travelers from around the world.\", 'original_response': \"Hmmm...I like a tropical climate. Think they need special education teachers? That's what I do.\", 'BEGIN': ['Hallucination'], 'VRM': ['Disclosure', 'Question', 'Ack.'], 'generated_response': []}\n",
            " 35% 78/222 [11:04<20:33,  8.57s/it]05/10/2023 02:44:03 - WARNING - generate - Empty generated response at 1254: {'dialog_idx': 281, 'response': 'On the visible spectrum, the color green is the color between blue and yellow.', 'history': ['i love the color green but i dont know a lot about it, what about you?'], 'knowledge': 'Green is the color between blue and yellow on the visible spectrum.', 'original_response': 'on the visible spectrum the color green is the color between blue and yellow', 'BEGIN': ['Entailment'], 'VRM': ['Edification'], 'generated_response': []}\n",
            " 69% 153/222 [21:34<09:14,  8.04s/it]05/10/2023 02:54:33 - WARNING - generate - Empty generated response at 2453: {'dialog_idx': 547, 'response': 'I also know that chemical plants have specialized units, equipment and also technology to use in the process of manufacturing', 'history': ['Just got a new job in a local factory, I start next week', 'Interesting. Will you work in a large warehouse with heavy equipment in it?', \"I don't know yep. What else do you know about factories ?\", 'Well, I know that factories can make discrete products and also can make materials like chemicals and refined oil products', 'Very interesting. I wonder how factories that manufacture chemicals are like.', 'Let me tell you , those factories that manufacture chemicals are frequently called plants and might have a some of their equipment placed outdoors', 'Thanks that is good info anything else you can tell me? this is really helping me to know what to expect'], 'knowledge': 'Chemical plants use specialized equipment, units, and technology in the manufacturing process.', 'original_response': 'Remember that chemical plants, if you do work in one, utilize specialized equipment, units, and technology all throughout their manufacturing process. So, you want to know what every single piece of equipment does and what every order of operation is, so that you know where you can mess up and how to avoid it, etc. Just take your time to study every step, and you should be fine.', 'BEGIN': ['Hallucination', 'Entailment'], 'VRM': ['Disclosure', 'Edification', 'Advisement'], 'generated_response': []}\n",
            " 70% 155/222 [21:51<09:21,  8.37s/it]05/10/2023 02:54:50 - WARNING - generate - Empty generated response at 2484: {'dialog_idx': 554, 'response': \"I can't confirm you that, but I know that dairy farms, in developed countries, consist typically of dairy cows that are high producing\", 'history': ['What is the difference between a family farm and a corporate farm?', 'Well, I know that there is a contrast with the farms that are operated as collectives or trusts', 'Very interesting.  Do family farms focus more on organic foods as opposed to corporate farms?', \"I can't confirm you that. But I know that the definition or concept doesn't translate easily from culture to culture, because there are differences in agricultural histories and traditions between countries\", 'Do you believe that Amish-owned farms be categorized as family famrs?', 'Well, I know that there are a lot of different Amish subgroups and most are conservative', 'Is it easy for family farms to be passed down in current American tax law?', 'Well, All I know is that corpotations and individuals are taxable, as well as trusts and estates which may be', 'Do you know if dairy products are produced on family farms?'], 'knowledge': 'In developed countries, dairy farms typically consist of high producing dairy cows.', 'original_response': 'One type of family farm is the dairy farm consisting of high producing dairy cows.', 'BEGIN': ['Hallucination'], 'VRM': ['Edification'], 'generated_response': []}\n",
            " 79% 176/222 [24:49<06:38,  8.67s/it]05/10/2023 02:57:49 - WARNING - generate - Empty generated response at 2830: {'dialog_idx': 631, 'response': \"Yeah. Did you know that a person that doesn't know the language of a foreign country they are in, is regarded as illiterate?\", 'history': [\"I just love Tuesdays! Don't you?\", \"Yeah. Did you know that the meaning of the name Tuesday is Tiw's Day ? It comes from Old english\", \"That's interesting. I bet a lot of cool things happen on Tuesdays.\", 'Yes. Have you ever wathced Agents of S.H.I.E.L.D ? It is a TV series for ABC', \"I actually haven't seen that show yet. It's on the ''list'' though. I always thought Tuesday would be a cool name. Do you know anyone named Tuesday?\", 'I do not. Do you know Anita Blake? This character has a necromancy power', 'Never heard of. I would love to read more about her.', 'Yeah. Speaking of reading. Did you know that the ability to write and read is called Literacy?', \"That's great! I like reading about anything having to do with history. So, history of literacy?\"], 'knowledge': 'A person who travels and resides in a foreign country but is unable to read or write in the language of the host country would also be regarded by the locals as being illiterate.', 'original_response': \"yes, I really like reading about other country's languages in case i ever get to travel to a foreign country. i should know their host language!\", 'BEGIN': ['Hallucination'], 'VRM': ['Disclosure', 'Ack.'], 'generated_response': []}\n",
            " 83% 184/222 [26:00<05:37,  8.88s/it]05/10/2023 02:58:58 - WARNING - generate - Empty generated response at 2948: {'dialog_idx': 658, 'response': '3 studio albums have been released. Which is your favorite ?', 'history': ['Are you in any band. My favourite is the story so far', 'I am not. I see they play pop punk rock. Do they play any other genre ?', 'Yes, but I love it more when someone is handling band.'], 'knowledge': 'They are currently signed with Pure Noise Records and have released 3 studio albums to date.', 'original_response': None, 'BEGIN': ['Entailment'], 'VRM': ['Question', 'Edification'], 'generated_response': []}\n",
            " 88% 195/222 [27:32<03:41,  8.20s/it]05/10/2023 03:00:32 - WARNING - generate - Empty generated response at 3130: {'dialog_idx': 699, 'response': \"Oh yes! That's one of the table top role-playing game.\", 'history': ['I love role playing games! It is so fun to just let go and be someone else for a bit.', 'Neat! Do you do literal acting in your role playing?', 'No, but I know you can. There are many different types of role playing games out there. Dungeons and Dragons is a popular one.'], 'knowledge': 'Dungeons & Dragons (abbreviated as D&D or DnD) is a fantasy tabletop role-playing game (RPG) originally designed by Gary Gygax and Dave Arneson.', 'original_response': None, 'BEGIN': ['Entailment'], 'VRM': ['Ack.', 'Edification'], 'generated_response': []}\n",
            "05/10/2023 03:00:32 - WARNING - generate - Empty generated response at 3135: {'dialog_idx': 700, 'response': 'Ah, yes. Did you know they were from Liverpool?', 'history': ['The Rolling Stones were such a great band.', \"Interesting. Do you think they're still a great band after Darryl Jones replaced Wyman in 1993?\", \"I think they're still good, but I just meant they were so notable in history.\", 'Yes, they were one of the first British Invasion bands and were associated with the 1960s counterculture.', 'Yeah, they were great. Of course, one of my all time favorite bands is The Beatles!'], 'knowledge': 'The Beatles were an English rock band formed in Liverpool in 1960.', 'original_response': 'The Beatles are the worst thing to come out of Liverpool if not all of the UK.', 'BEGIN': ['Hallucination'], 'VRM': ['Disclosure'], 'generated_response': []}\n",
            " 90% 199/222 [28:07<03:16,  8.53s/it]05/10/2023 03:01:09 - WARNING - generate - Empty generated response at 3186: {'dialog_idx': 712, 'response': 'Well, I also know that is is classified as an oil crop and grain legume as well', 'history': ['What are  peanuts', 'Well, as far as I know a peanut is classified as a legume crop', 'Please how do they look like', 'I am not sure about that. But I kow that they are grown for the edible seed mainly', 'Interesting. What else do you know?'], 'knowledge': 'It is classified as both a grain legume and, because of its high oil content, an oil crop.', 'original_response': \"So it a legume- which means that it's very solid and kind of oily. It is like a combination of a garbanzo bean and an almond.\", 'BEGIN': ['Hallucination'], 'VRM': ['Edification'], 'generated_response': []}\n",
            "100% 222/222 [31:22<00:00,  8.48s/it]\n"
          ]
        }
      ],
      "source": [
        "!python /content/FaithDial/models/generate.py --model_name_or_path /content/best_model --do_sample --top_p 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uiVB4BMxygM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}